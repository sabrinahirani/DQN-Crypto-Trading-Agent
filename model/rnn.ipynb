{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "data = pd.read_csv(\"./data/BTC-USD-1d.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MinMaxScalerS' from 'sklearn.preprocessing' (c:\\Users\\sabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 38\u001b[0m\n\u001b[0;32m     29\u001b[0m data_set\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#print(data_set.shape)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#print(data.shape)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#print(type(data_set))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#print(yi)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#print(len(yi))\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScalerS\n\u001b[0;32m     39\u001b[0m sc \u001b[38;5;241m=\u001b[39m MinMaxScaler(feature_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     40\u001b[0m data_set_scaled \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mfit_transform(data_set)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'MinMaxScalerS' from 'sklearn.preprocessing' (c:\\Users\\sabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "# data = yf.download(tickers = '^RUI', start = '2012-03-11',end = '2022-07-10')\n",
    "data = pd.read_csv(\"./data/BTC-USD-1d.csv\")\n",
    "\n",
    "data.head(10)\n",
    "# Adding indicators\n",
    "data['RSI']=ta.rsi(data.Close, length=15)\n",
    "data['EMAF']=ta.ema(data.Close, length=20)\n",
    "data['EMAM']=ta.ema(data.Close, length=100)\n",
    "data['EMAS']=ta.ema(data.Close, length=150)\n",
    "\n",
    "data['Target'] = data['Adj Close']-data.Open\n",
    "data['Target'] = data['Target'].shift(-1)\n",
    "\n",
    "data['TargetClass'] = [1 if data.Target[i]>0 else 0 for i in range(len(data))]\n",
    "\n",
    "data['TargetNextClose'] = data['Adj Close'].shift(-1)\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(inplace = True)\n",
    "data.drop(['Volume', 'Close', 'Date'], axis=1, inplace=True)\n",
    "data_set = data.iloc[:, 0:11]#.values\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data_set.head(20)\n",
    "#print(data_set.shape)\n",
    "#print(data.shape)\n",
    "#print(type(data_set))\n",
    "#Target column Categories\n",
    "#y =[1 if data.Open[i]>data.Close[i] else 0 for i in range(0, len(data))]\n",
    "#yi = [data.Open[i]-data.Close[i] for i in range(0, len(data))]\n",
    "#print(yi)\n",
    "#print(len(yi))\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "data_set_scaled = sc.fit_transform(data_set)\n",
    "print(data_set_scaled)\n",
    "# multiple feature from data provided to the model\n",
    "X = []\n",
    "#print(data_set_scaled[0].size)\n",
    "#data_set_scaled=data_set.values\n",
    "backcandles = 30\n",
    "print(data_set_scaled.shape[0])\n",
    "for j in range(8):#data_set_scaled[0].size):#2 columns are target not X\n",
    "    X.append([])\n",
    "    for i in range(backcandles, data_set_scaled.shape[0]):#backcandles+2\n",
    "        X[j].append(data_set_scaled[i-backcandles:i, j])\n",
    "\n",
    "#move axis from 0 to position 2\n",
    "X=np.moveaxis(X, [0], [2])\n",
    "\n",
    "#Erase first elements of y because of backcandles to match X length\n",
    "#del(yi[0:backcandles])\n",
    "#X, yi = np.array(X), np.array(yi)\n",
    "# Choose -1 for last column, classification else -2...\n",
    "X, yi =np.array(X), np.array(data_set_scaled[backcandles:,-1])\n",
    "y=np.reshape(yi,(len(yi),1))\n",
    "#y=sc.fit_transform(yi)\n",
    "#X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(y)\n",
    "print(y.shape)\n",
    "#also comprehensions for X\n",
    "#X = np.array([data_set_scaled[i-backcandles:i,:4].copy() for i in range(backcandles,len(data_set_scaled))])\n",
    "#print(X)\n",
    "#print(X.shape)\n",
    "# split data into train test sets\n",
    "splitlimit = int(len(X)*0.8)\n",
    "print(splitlimit)\n",
    "X_train, X_test = X[:splitlimit], X[splitlimit:]\n",
    "y_train, y_test = y[:splitlimit], y[splitlimit:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.callbacks import History\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\n",
    "import numpy as np\n",
    "#tf.random.set_seed(20)\n",
    "np.random.seed(10)\n",
    "\n",
    "lstm_input = Input(shape=(backcandles, 8), name='lstm_input')\n",
    "inputs = LSTM(150, name='first_layer')(lstm_input)\n",
    "inputs = Dense(1, name='dense_layer')(inputs)\n",
    "output = Activation('linear', name='output')(inputs)\n",
    "model = Model(inputs=lstm_input, outputs=output)\n",
    "adam = optimizers.Adam()\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "model.fit(x=X_train, y=y_train, batch_size=15, epochs=30, shuffle=True, validation_split = 0.1)\n",
    "y_pred = model.predict(X_test)\n",
    "#y_pred=np.where(y_pred > 0.43, 1,0)\n",
    "for i in range(10):\n",
    "    print(y_pred[i], y_test[i])\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_test, color = 'black', label = 'Test')\n",
    "plt.plot(y_pred, color = 'green', label = 'pred')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca221243c386e296bca21c5e5b7d333346a49727a9bf6dcde7990470b6f224e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
